{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, json\n",
    "from datetime import datetime\n",
    "import boto3\n",
    "import pandas as pd\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OCR Section\n",
    "- In this section, we loop through all the files in our data folder, to extract any and all information in the PDF we have. We use Google Cloud (GCP) for this. However, you can switch to any other cloud OCR model of your choice. You will have to create your own GCP project, and use your credentials (GCP provides $300 free credits for all users, for 3 momths)\n",
    "- To note:\n",
    "     -  In this project, the professor had no use case for the first page of every pdf, so the code explicitly skips the first page (0 in python index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import GCP credentials from file\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"name of your own json with GCP credentials\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import time\n",
    "import fitz\n",
    "from google.cloud import vision\n",
    "\n",
    "# ---------------------\n",
    "# CONFIG\n",
    "# ---------------------\n",
    "\n",
    "DATA_DIR = \"Newsletter_OCR_LLM_Project/Data\"\n",
    "OUTPUT_DIR = os.path.join(DATA_DIR, \"OCR_versions\")\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "PAGES_TO_SKIP = {0}       # PDF page indexes to skip (0-based)\n",
    "SLEEP_BETWEEN_CALLS = 0.5 # seconds between API calls\n",
    "\n",
    "client = vision.ImageAnnotatorClient()\n",
    "\n",
    "#Looping files for OCR\n",
    "\n",
    "pdf_files = sorted([f for f in os.listdir(DATA_DIR) if f.lower().endswith(\".pdf\")])\n",
    "\n",
    "print(f\"Found {len(pdf_files)} PDF files.\\n\")\n",
    "\n",
    "for file_name in pdf_files:\n",
    "    pdf_path = os.path.join(DATA_DIR, file_name)\n",
    "\n",
    "    # Output filename: <original>_ocr.txt\n",
    "    base_name = os.path.splitext(file_name)[0]\n",
    "    out_path = os.path.join(OUTPUT_DIR, f\"{base_name}_ocr.txt\")\n",
    "\n",
    "    # Skip if OCR file already exists\n",
    "    if os.path.exists(out_path):\n",
    "        print(f\"Skipping (already OCR'd): {file_name}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing: {file_name}\")\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    all_text = []\n",
    "    newsletter_page_no = 0\n",
    "\n",
    "    for pdf_index in range(len(doc)):\n",
    "        if pdf_index in PAGES_TO_SKIP:\n",
    "            continue\n",
    "\n",
    "        newsletter_page_no += 1\n",
    "        page = doc.load_page(pdf_index)\n",
    "\n",
    "        # Render page to image\n",
    "        pix = page.get_pixmap(dpi=300)\n",
    "        img_bytes = io.BytesIO(pix.tobytes(\"png\"))\n",
    "        image = vision.Image(content=img_bytes.getvalue())\n",
    "\n",
    "        # OCR call\n",
    "        response = client.document_text_detection(image=image)\n",
    "\n",
    "        # Extract text robustly\n",
    "        text = \"\"\n",
    "        if response.full_text_annotation and response.full_text_annotation.text:\n",
    "            text = response.full_text_annotation.text\n",
    "        elif response.text_annotations:\n",
    "            text = response.text_annotations[0].description\n",
    "\n",
    "        # Annotate for clarity\n",
    "        all_text.append(\n",
    "            f\"\\n--- Newsletter Page {newsletter_page_no} (PDF page {pdf_index + 1}) ---\\n{text}\"\n",
    "        )\n",
    "\n",
    "        time.sleep(SLEEP_BETWEEN_CALLS)\n",
    "\n",
    "    # Save OCR text\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.writelines(all_text)\n",
    "\n",
    "    print(f\"Saved → {out_path}\\n\")\n",
    "\n",
    "print(\"All PDFs processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at your OCR utput\n",
    "path = \"PATH TO OUTPUT HERE\"\n",
    "\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The output here is all in a single column, and has certain errors in heirarchy. We need to make sure that any information that is extracted or parsed, has the correct creditentials for each article. To fix this, we use an LLM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Parsed versions\n",
    "### - To now create parsed versions, we write a prompt to instruct the LLM to re format the OCR version into a parsable version. We also ask for metada extraction, so that every volume, is clearly marked. Every article/review etc will first start with metadata, detailing information such as atuhor, date, the type of information presented and the volume and issue number. Eack artile will then become parsable as the metadata acts as a delimitter, making database creation easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the Prompt:\n",
    "PROMPT = \"\"\" \n",
    "You are an archivist re-structuring OCR text from historical newsletters.\n",
    "\n",
    "You will receive the full OCR text (from Google Cloud Vision) for an issue of the *Women Artists Newsletter*.\n",
    "The OCR text is accurate but unformatted. Your job is to **reconstruct the structure without changing, summarizing, or omitting any content.**\n",
    "\n",
    "---\n",
    "\n",
    "### GOAL\n",
    "Produce a single, plain-text file that:\n",
    "- contains **every word** of the OCR text, exactly as recognized;\n",
    "- merges “continued on page …” segments into one continuous article;\n",
    "- organizes all sections by category (masthead, articles, calendar, advertisements);\n",
    "- formats each section using a clear, simple, line-based structure.\n",
    "\n",
    "---\n",
    "\n",
    "### RULES\n",
    "\n",
    "1. **Do not summarize, paraphrase, or skip content.**\n",
    "   Include every line and paragraph from the OCR text verbatim.Please make sure you finish the articles. Do not summarise. I need the ocr versions to be reformatted for readbale use. \n",
    "\n",
    "2. **Correct structure only.**\n",
    "   - If a byline (e.g., “--Judy Seigel” or “Written by …”) appears misplaced, attach it to the correct article.\n",
    "   - Merge multi-page articles that were split across OCR pages.\n",
    "   - Preserve bullet lists, calendars, and exhibition entries exactly.\n",
    "   - The final look should be smooth paragraphs, they should not look like a column, but properly formatted to look. \n",
    "\n",
    "3. **Categorize each section** as one of the following types:\n",
    "   - MASTHEAD  \n",
    "   - ARTICLE  \n",
    "   - CALENDAR  \n",
    "   - ADVERTISEMENT  \n",
    "   - EDITORIAL\n",
    "   - REVIEW\n",
    "   - PANEL\n",
    "   - LETTER\n",
    "   - SUBSCRIPTION\n",
    "\n",
    "4. **Output order:**\n",
    "   1. Masthead / Index (if present)  \n",
    "   2. Articles  \n",
    "   3. Calendar / Exhibitions  \n",
    "   4. Advertisements / Subscriptions  \n",
    "\n",
    "5. **Output format:**\n",
    "   Each section should be separated by one blank line and follow this simple labeled structure:\n",
    "\n",
    "    TITLE: <exact title as printed>\n",
    "    WRITER: <writer(s) if visible, otherwise \"unknown\">\n",
    "    PAGE_NUMBERS: <newsletter page numbers>\n",
    "    VOLUME: <volume number>\n",
    "    ISSUE: <issue number>\n",
    "    SEASON_YEAR: <season and year, e.g., April 1975>\n",
    "    TYPE: <<article | editorial | review | letter | calendar | advertisement | masthead | subscription | panel>\n",
    "    CONTENT:\n",
    "    <verbatim OCR text of this section, with full paragraphs and lists preserved>\n",
    "\n",
    "\n",
    "6. **Formatting details:**\n",
    "- Do not include extra symbols, brackets, or markers.\n",
    "- Keep one blank line between sections.\n",
    "- Preserve all paragraph breaks and spacing from the OCR text.\n",
    "- Output should be plain text, not JSON or Markdown.\n",
    "\n",
    "---\n",
    "\n",
    "### EXAMPLE OUTPUT\n",
    "\n",
    "TITLE: ARTISTS, DEALERS AND ECONOMICS AT A.I.R. APRIL 7TH  \n",
    "WRITER: Judy Seigel  \n",
    "PAGE_NUMBERS: 1–2  \n",
    "VOLUME: 1  \n",
    "ISSUE: 1  \n",
    "SEASON_YEAR: April 1975  \n",
    "TYPE: ARTICLE  \n",
    "CONTENT:  \n",
    "Art Dealers Rosa Esman, Betty Parsons and Virginia Zabriskie, artists Rosemarie Castoro and Laurace James, \n",
    "and moderator Maude Boltz opened the Third year of A.I.R.’s Monday evening programs.  \n",
    "They offered a candid and engaging discussion of the economics of art and the realities of sustaining creative work...  \n",
    "\n",
    "TITLE: CALENDAR–EXHIBITIONS  \n",
    "WRITER: unknown  \n",
    "PAGE_NUMBERS: 3–4  \n",
    "VOLUME: 1  \n",
    "ISSUE: 1  \n",
    "SEASON_YEAR: April 1975  \n",
    "TYPE: CALENDAR  \n",
    "CONTENT:  \n",
    "CECILE ABISH – “Shifting Concern,” Douglass College Campus, New Brunswick, NJ, through May 31.  \n",
    "PATRICIA ADAMS – Paintings on unstretched canvases, Central Hall Gallery, Port Washington, NY, through April 27.  \n",
    "ROSEMARIE BECK – Poindexter Gallery, 24 E. 84 St., New York, April 22–May 10.  \n",
    "(…full list continues)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We connect to LLM's using Portkey, the following code initializes and helps to check if your system is connected. If you timeout, Please check to see you are either using NYU VPN, or the NYU wifi.\n",
    "\n",
    "from portkey_ai import Portkey\n",
    "\n",
    "portkey = Portkey(\n",
    "  base_url = \"https://ai-gateway.apps.cloud.rt.nyu.edu/v1\",\n",
    "  api_key = \"YOUR OWN API KEY HERE\"\n",
    ")\n",
    "\n",
    "response = portkey.chat.completions.create(\n",
    "    model = \"@gpt-4o/gpt-4o\",\n",
    "    messages = [\n",
    "      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "      {\"role\": \"user\", \"content\": \"What is Portkey\"}\n",
    "    ],\n",
    "    MAX_TOKENS = 512\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great! You got a response! \n",
    "- #### If you did not get any reponse, please make sure of the following:\n",
    "\n",
    "    - You are within the NYU environment (either via WIFI or VPN)\n",
    "    - You have the correct API key input in the code\n",
    "    - You are using a model you have access too (can check this in the \"model catalog\" section of the menu)\n",
    "    - You are in the correct workspace (top left corner of the portkey page)\n",
    "    - You are in the correct organisation (bottom left corner of the portkey page)\n",
    "    - You are NOT using Google Collab. (Google collab works in it's own separate environment, NYU VPN/WIFI will NOT help in connecting to the correct environment)\n",
    "\n",
    "\n",
    "\n",
    "- #### If you passed all of these checks, and are still timing out, or getting an un known error, you should a) check Portkey Documentation for any important infomration, b) Contact the person who helped you with getting portkey resources. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's now run the code to make a parsable version of the OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from portkey_ai import Portkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format_newsletter_single_file.py\n",
    "import os\n",
    "from portkey_ai import Portkey\n",
    "\n",
    "# === Input and output paths ===\n",
    "INPUT_FILE = \"Newsletter_OCR_LLM_Project/OCR_versions/1976_06-01_Vol.2_No.3_compressed_ocr.txt\"\n",
    "OUTPUT_DIR = \"Newsletter_OCR_LLM_Project/parsable_versions\"\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# === Portkey setup ===\n",
    "portkey = Portkey(\n",
    "    base_url=\"https://ai-gateway.apps.cloud.rt.nyu.edu/v1\",\n",
    "    api_key=\"YOUR API KEY HERE\",\n",
    ")\n",
    "\n",
    "MODEL = \"@bedrock/us.anthropic.claude-sonnet-4-20250514-v1:0\"\n",
    "MAX_TOKENS = 16384\n",
    "\n",
    "# === Derive output filename ===\n",
    "filename = os.path.basename(INPUT_FILE)\n",
    "\n",
    "base = filename.replace(\"_compressed_ocr\", \"\")\n",
    "out_name = base.replace(\".txt\", \"_parsable.txt\")\n",
    "\n",
    "output_path = os.path.join(OUTPUT_DIR, out_name)\n",
    "\n",
    "print(f\"\\nProcessing → {filename}\")\n",
    "\n",
    "# === Load OCR text ===\n",
    "with open(INPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    ocr_text = f.read().replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "\n",
    "# === Construct messages ===\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": f\"{PROMPT}\\n\\nHere is the OCR text for the full newsletter:\\n\\n{ocr_text}\"}\n",
    "]\n",
    "\n",
    "# === Generate completion ===\n",
    "completion = portkey.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=MODEL,\n",
    "    max_tokens=MAX_TOKENS,\n",
    ")\n",
    "\n",
    "readable_text = completion.choices[0].message.get(\"content\", \"\")\n",
    "\n",
    "# === Save output ===\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(readable_text)\n",
    "\n",
    "print(f\"✔ Saved → {output_path}\")\n",
    "print(\"\\nSingle file processed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format_newsletter_full_issue_txt_loop.py\n",
    "import os\n",
    "from portkey_ai import Portkey\n",
    "\n",
    "# === Input and output directories ===\n",
    "INPUT_DIR = \"Newsletter_OCR_LLM_Project/OCR_versions\"\n",
    "OUTPUT_DIR = \"Newsletter_OCR_LLM_Project/parsable_versions\"\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# === Portkey setup ===\n",
    "portkey = Portkey(\n",
    "    base_url=\"https://ai-gateway.apps.cloud.rt.nyu.edu/v1\",\n",
    "    api_key=\"YOUR API KEY HERE\",\n",
    ")\n",
    "\n",
    "MODEL = \"@bedrock/us.anthropic.claude-sonnet-4-20250514-v1:0\"\n",
    "MAX_TOKENS = 16384\n",
    "\n",
    "# === Loop through all OCR files ===\n",
    "for filename in os.listdir(INPUT_DIR):\n",
    "\n",
    "    if not filename.endswith(\".txt\"):\n",
    "        continue  \n",
    "\n",
    "    input_path = os.path.join(INPUT_DIR, filename)\n",
    "\n",
    "    # Output filename: replace _ocr with _parsable\n",
    "    base = filename.replace(\"_compressed_ocr\", \"\")\n",
    "    out_name = base.replace(\".txt\", \"_parsable.txt\")\n",
    "    output_path = os.path.join(OUTPUT_DIR, out_name)\n",
    "\n",
    "    print(f\"\\nProcessing → {filename}\")\n",
    "\n",
    "    # Load OCR text\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        ocr_text = f.read().replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "\n",
    "    # Construct messages\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": f\"{PROMPT}\\n\\nHere is the OCR text for the full newsletter:\\n\\n{ocr_text}\"}\n",
    "    ]\n",
    "\n",
    "    # Generate completion\n",
    "    completion = portkey.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=MODEL,\n",
    "        max_tokens=MAX_TOKENS,\n",
    "    )\n",
    "\n",
    "    readable_text = completion.choices[0].message.get(\"content\", \"\")\n",
    "\n",
    "    # Save formatted output\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(readable_text)\n",
    "\n",
    "    print(f\"Saved → {output_path}\")\n",
    "\n",
    "print(\"\\nAll files processed successfully!\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's have a look at the file, and you should see the metadata extraction\n",
    "- This file was then shared with a software engineer, who parsed all the different articles, authros etc, and turned it onto an online database, for the given dataset (can be seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Newsletter_OCR_LLM_Project/parsable_versions/Vol_4_Issue_9_parsable.txt\"\n",
    "\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus use case: Indexing. \n",
    "- The original aim of this project was to create indexes for each newsletter, this was created directly from the OCR files, in the code cells below, is the prompt to create an index, and the code to run the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indexing Prompt\n",
    "index_prompt_text = \"\"\"\n",
    "You are an archivist assistant working with OCR-extracted content from historical feminist newsletters.\n",
    "\n",
    "Your task is to create a structured, article-wise index from the provided OCR JSON data of a newsletter issue.\n",
    "\n",
    "---\n",
    "\n",
    "Your output must contain these sections, in order:\n",
    "\n",
    "### 1. CONTRIBUTORS:\n",
    "List all contributors (people who wrote or signed articles, letters, editorials, reviews, or are explicitly listed in mastheads).  \n",
    "Format:\n",
    "- <Name> (role or contribution, e.g., \"publisher and editor,\" \"review author of Ellen Banks,\" \"contributing editor\")  \n",
    "\n",
    "Include contributors found in:\n",
    "- Mastheads, staff boxes, editorial credits\n",
    "- Signed articles, reviews, or letters  \n",
    "Do **not** include people who are only mentioned in passing.  \n",
    "\n",
    "---\n",
    "\n",
    "### 2. PEOPLE SUBSTANTIALLY COVERED:\n",
    "List individuals who are the primary focus of an article, review, or extended discussion (e.g., a featured artist, critic, or theorist).  \n",
    "Format:\n",
    "- <Name> (short note on how they are covered, e.g., \"subject of review,\" \"artist featured in exhibition\"), in \"<Article Title>\"  \n",
    "\n",
    "This section highlights people who are written about in depth.  \n",
    "Do **not** include individuals who are only briefly cited or quoted.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. ARTICLE INDEX:\n",
    "List every article in the issue in order of appearance.  \n",
    "For each article, provide:\n",
    "- Article Title (as printed)  \n",
    "- Author(s)  \n",
    "- Primary subjects (artists, exhibitions, or movements discussed)  \n",
    "\n",
    "Do not summarize the article — just capture title, author, and subjects.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. CALENDAR EXHIBITIONS:\n",
    "List all artists, galleries, or exhibition spaces that appear under calendar- or listing-type sections (e.g., “Calendar,” “Exhibitions,” “Events, Conferences & Symposia,” “Listings”).  \n",
    "Format:\n",
    "- <Artist or Entity Name> (<exact section heading>)\n",
    "\n",
    "Do not duplicate these entries in the Article Index.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. ADVERTISEMENTS:\n",
    "List all persons, groups, or businesses mentioned on pages flagged as advertisements.  \n",
    "Format:\n",
    "- adv(<name or entity>)\n",
    "\n",
    "---\n",
    "\n",
    "### GENERAL INSTRUCTIONS:\n",
    "- Do not organize by page number—organize by **article and section**.  \n",
    "- Use the newsletter’s stated volume, issue, and season/year where needed (do not infer).  \n",
    "- Alphabetize entries within each section except the Article Index (which should follow the order of appearance).  \n",
    "- For names, always include a short, research-useful note on their role or coverage — avoid vague filler.  \n",
    "- Output must be plain, human-readable, and copy-paste friendly.  \n",
    "- End the index with \"the index ends here\".\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text file saved → Vol_1_Issue_8_index.txt\n"
     ]
    }
   ],
   "source": [
    "from portkey_ai import Portkey\n",
    "\n",
    "portkey = Portkey(\n",
    "    base_url=\"https://ai-gateway.apps.cloud.rt.nyu.edu/v1\",\n",
    "    api_key= \"YOUR API KEY HERE\" \n",
    ")\n",
    "\n",
    "# --- File paths ---\n",
    "OCR_PATH = \"/Users/jovitagandhi/Desktop/JoFo/Education/Masters/NYU/RA_Gen_AI/OCR_Books/Newsletter_OCR_LLM_Project/OCR_versions/1976_01-01_Vol.1_No.8_compressed_ocr.txt\"\n",
    "OUT_FILE = \"Vol_1_Issue_8_index.txt\"   \n",
    "\n",
    "MODEL =  \"@bedrock/us.anthropic.claude-sonnet-4-20250514-v1:0\" \n",
    "MAX_TOKENS = 16384 \n",
    "\n",
    "# --- Load OCR text ---\n",
    "with open(OCR_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    ocr_text = f.read().replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "\n",
    "# --- Construct messages ---\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": f\"{index_prompt_text}\\n\\nHere is the OCR text for the full newsletter:\\n\\n{ocr_text}\"}\n",
    "]\n",
    "\n",
    "# --- Generate completion ---\n",
    "completion = portkey.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=MODEL,\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# --- Extract content safely ---\n",
    "readable_text = (\n",
    "    getattr(completion.choices[0].message, \"content\", \"\")\n",
    "    or completion.choices[0].message.get(\"content\", \"\")\n",
    ")\n",
    "\n",
    "# --- Save as plain text ---\n",
    "with open(OUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(readable_text)\n",
    "\n",
    "print(f\"Text file saved → {OUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"YOUR_FILE_PATH\"\n",
    "\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "video",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "758b54b07f4628f2981a93ec2fa893cf8f1006e199b2e47f7b9610a507fb2008"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
